{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SV6yxemOMImZ"
      },
      "outputs": [],
      "source": [
        "import os, re, csv, math, codecs, logging\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# from keras.metrics import F1Score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "class_num = 20"
      ],
      "metadata": {
        "id": "bLIBiYTDMK1M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# descargamos los embeddings de palabras de Fasttext para inglés y descomprimimos el archivo.\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaGySH-aMLyx",
        "outputId": "8007cfad-786b-420b-b636-04eb086278fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-27 01:10:08--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.15, 108.157.254.121, 108.157.254.124, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M   186MB/s    in 3.5s    \n",
            "\n",
            "2024-06-27 01:10:12 (187 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los embeddings de palabras\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print(f'found {len(embeddings_index)} word vectors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjXJFdFxMOXS",
        "outputId": "a02a0209-944d-40ed-8e3d-6e9143e11286"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n",
            "found 999995 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciamos el tokenizador\n",
        "token = Tokenizer(num_words=300000,\n",
        "                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                lower=True,\n",
        "                split=' ',\n",
        "                char_level=False,\n",
        "                oov_token=\"UNK\",\n",
        "                document_count=0)"
      ],
      "metadata": {
        "id": "mXtShmvsMQL8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fiteamos el tokenizador\n",
        "token.fit_on_texts(newsgroups_train.data)"
      ],
      "metadata": {
        "id": "-C5LjTn7MR6y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos los diccionarios idx2word y word2idx\n",
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "# CHECK QUE EMPIEZA POR 0"
      ],
      "metadata": {
        "id": "O85QvLdaMVEA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos en una matriz los embeddings de las palabras\n",
        "# presentes en el vocabulario\n",
        "embed_dim=300\n",
        "num_words=len(dictionary)+1\n",
        "embedding_matrix=np.zeros([num_words,embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if idx <= num_words and word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ],
      "metadata": {
        "id": "0aP8v-dZMWrA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-J1ibkgMY_k",
        "outputId": "b7282897-59c4-41b7-9f2b-459f058e7715"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105374, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# se tokenizan los textos\n",
        "train_sequences=token.texts_to_sequences(newsgroups_train.data)\n",
        "test_sequences=token.texts_to_sequences(newsgroups_test.data)"
      ],
      "metadata": {
        "id": "VePZXjr1Maki"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En este punto seleccionamos el tamaño de contexto a procesar en la variable `max_len`\n",
        "max_len = 500\n",
        "train_sequences=pad_sequences(train_sequences,maxlen=max_len)\n",
        "test_sequences=pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "vb6BxFptMcCM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional, LSTM, GRU, Dense, Embedding, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import L2"
      ],
      "metadata": {
        "id": "hktM5pOhMfFi"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embed_dim, weights=[embedding_matrix], input_length=None, trainable=False))\n",
        "\n",
        "model.add(Bidirectional(GRU(200, return_sequences=True)))\n",
        "\n",
        "model.add(Bidirectional(GRU(100)))\n",
        "\n",
        "model.add(Dense(class_num, activation='softmax'))\n",
        "\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(learning_rate = 0.001), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5QSXxIMMhEF",
        "outputId": "598b3ea5-e2db-4cf5-cc28-4fa2635e6850"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, None, 300)         31612200  \n",
            "                                                                 \n",
            " bidirectional_37 (Bidirect  (None, None, 400)         602400    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_38 (Bidirect  (None, 200)               301200    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 20)                4020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32519820 (124.05 MB)\n",
            "Trainable params: 907620 (3.46 MB)\n",
            "Non-trainable params: 31612200 (120.59 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\",\n",
        "    min_delta=0,\n",
        "    patience=8,\n",
        "    verbose=0,\n",
        "    mode=\"max\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0,\n",
        ")\n",
        "reducelr = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "    patience=2,\n",
        "    factor=0.5\n",
        ")\n",
        "\n",
        "history = model.fit(train_sequences, newsgroups_train.target,\n",
        "                    batch_size=128,\n",
        "                    epochs=100,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping, reducelr]\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPwxQgjxMo6o",
        "outputId": "f64aec36-9f29-4d69-d90f-8a3914790716"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "71/71 [==============================] - 23s 235ms/step - loss: 2.6816 - accuracy: 0.1316 - val_loss: 2.3267 - val_accuracy: 0.2240 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 16s 223ms/step - loss: 2.0903 - accuracy: 0.2816 - val_loss: 1.9478 - val_accuracy: 0.3243 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 15s 217ms/step - loss: 1.6809 - accuracy: 0.4183 - val_loss: 1.5567 - val_accuracy: 0.4565 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 1.4153 - accuracy: 0.5109 - val_loss: 1.4369 - val_accuracy: 0.5064 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 1.2532 - accuracy: 0.5715 - val_loss: 1.3286 - val_accuracy: 0.5479 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 1.1325 - accuracy: 0.6247 - val_loss: 1.2236 - val_accuracy: 0.5895 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 15s 217ms/step - loss: 1.0412 - accuracy: 0.6537 - val_loss: 1.2027 - val_accuracy: 0.6151 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 16s 220ms/step - loss: 0.9471 - accuracy: 0.6914 - val_loss: 1.1389 - val_accuracy: 0.6315 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.8669 - accuracy: 0.7170 - val_loss: 1.1301 - val_accuracy: 0.6460 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.8042 - accuracy: 0.7372 - val_loss: 1.0765 - val_accuracy: 0.6699 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 0.7437 - accuracy: 0.7639 - val_loss: 1.1110 - val_accuracy: 0.6580 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 15s 213ms/step - loss: 0.6738 - accuracy: 0.7864 - val_loss: 1.1152 - val_accuracy: 0.6655 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.5652 - accuracy: 0.8229 - val_loss: 1.0903 - val_accuracy: 0.6752 - lr: 5.0000e-04\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.5201 - accuracy: 0.8369 - val_loss: 1.1120 - val_accuracy: 0.6703 - lr: 5.0000e-04\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 0.4814 - accuracy: 0.8511 - val_loss: 1.1314 - val_accuracy: 0.6677 - lr: 5.0000e-04\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.4339 - accuracy: 0.8715 - val_loss: 1.1495 - val_accuracy: 0.6708 - lr: 2.5000e-04\n",
            "Epoch 17/100\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.4122 - accuracy: 0.8770 - val_loss: 1.1512 - val_accuracy: 0.6695 - lr: 2.5000e-04\n",
            "Epoch 18/100\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.3850 - accuracy: 0.8895 - val_loss: 1.1666 - val_accuracy: 0.6743 - lr: 1.2500e-04\n",
            "Epoch 19/100\n",
            "71/71 [==============================] - 16s 221ms/step - loss: 0.3735 - accuracy: 0.8929 - val_loss: 1.1629 - val_accuracy: 0.6765 - lr: 1.2500e-04\n",
            "Epoch 20/100\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.3631 - accuracy: 0.8956 - val_loss: 1.1762 - val_accuracy: 0.6765 - lr: 1.2500e-04\n",
            "Epoch 21/100\n",
            "71/71 [==============================] - 15s 217ms/step - loss: 0.3546 - accuracy: 0.9006 - val_loss: 1.1958 - val_accuracy: 0.6690 - lr: 1.2500e-04\n",
            "Epoch 22/100\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.3412 - accuracy: 0.9056 - val_loss: 1.1959 - val_accuracy: 0.6717 - lr: 6.2500e-05\n",
            "Epoch 23/100\n",
            "71/71 [==============================] - 15s 215ms/step - loss: 0.3359 - accuracy: 0.9070 - val_loss: 1.2006 - val_accuracy: 0.6726 - lr: 6.2500e-05\n",
            "Epoch 24/100\n",
            "71/71 [==============================] - 15s 216ms/step - loss: 0.3287 - accuracy: 0.9104 - val_loss: 1.2060 - val_accuracy: 0.6703 - lr: 3.1250e-05\n",
            "Epoch 25/100\n",
            "71/71 [==============================] - 15s 214ms/step - loss: 0.3261 - accuracy: 0.9108 - val_loss: 1.2026 - val_accuracy: 0.6734 - lr: 3.1250e-05\n",
            "Epoch 26/100\n",
            "71/71 [==============================] - 15s 217ms/step - loss: 0.3229 - accuracy: 0.9122 - val_loss: 1.2057 - val_accuracy: 0.6726 - lr: 1.5625e-05\n",
            "Epoch 27/100\n",
            "71/71 [==============================] - 16s 220ms/step - loss: 0.3216 - accuracy: 0.9125 - val_loss: 1.2080 - val_accuracy: 0.6712 - lr: 1.5625e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Medir F1-score en test\n",
        "from sklearn.metrics import f1_score\n",
        "y_pred = model.predict(test_sequences)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = newsgroups_test.target\n",
        "f1_score(y_test, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lccx4gSQMphF",
        "outputId": "650c7705-7788-42ee-d716-dc71f9f3c2a6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 11s 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6039619342492413"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}